"""\
Precalculate a set of origins to use for training transformation prediction
models.

Usage:
    ap_choose_origins init <pisces_path> [-o <path>] [-f] [-n <atoms>]
        [-r <radius>]
    ap_choose_origins calc <output_dir> [<num_workers> <worker_id>]
    ap_choose_origins finish <output_dir> [-d]

Arguments:
    <pisces_path>
        A path to a file specifying a subset of the PDB, as generated by the 
        PISCES web server.

    <output_dir>
        The path to the directory created by `ap_choose_origins init`, which 
        contains the input parameters and any output data frames.

Options:
    -o --output-path <path>     [default: %]
        The name of the directory to write the chosen origins to.  '%' will be 
        replaced by a long string containing a number of details about how the 
        origins were selected, including sequence identity, resolution, nearby 
        atom thresholds, etc.

    -f --force
        If the output path already exists, overwrite it.  Otherwise, the 
        program will abort.
        
    -n --min-nearby-atoms <int>    [default: 25]
        How many atoms must be in the vicinity of a point in order for that 
        point to be considered as an origin.  Note that only "biological" atoms 
        are included in this count; atoms belonging to common crystallographic 
        contaminants like water, glycerol, etc. are excluded.  The default is 
        appropriate for a 5Ã… radius, and was empirically chosen to get origins 
        that are mostly surrounded by biological atoms.  See also `--radius`.

    -r --radius <angstroms>     [default: 5]
        The radius, in units of Angstroms, of the sphere around each potential 
        atoms in which to count atoms.  See also `--min-nearby-atoms`.

    -d --dry-run
        Show status information about any completed/pending jobs, but don't 
        actually write the consolidated files or delete the unconsolidated 
        ones.

Environment variables:
    PDB_DIR
        The path a directory containing every necessary structure, in the MMCIF 
        format.  
"""

import docopt
from .neighbor_count import (
        OriginParams, choose_origins_for_tags, save_origins,
        save_origin_params, load_origin_params, consolidate_origins,
)
from ..atoms import load_pisces, parse_pisces_path
from pathlib import Path
from more_itertools import nth, chunked
from dataclasses import asdict
from functools import partial
from tqdm import tqdm

def main():
    args = docopt.docopt(__doc__)

    if args['init']:
        pisces_path = Path(args['<pisces_path>'])
        pisces_df = load_pisces(pisces_path)
        origin_params = OriginParams(
                radius_A=float(args['--radius']),
                min_nearby_atoms=int(args['--min-nearby-atoms']),
        )
        path_params = {
                **parse_pisces_path(pisces_path),
                **asdict(origin_params),
        }
        default_output_path = (
                'origins_max_identity_{max_percent_identity}_'
                'max_resolution_{max_resolution_A}_'
                'min_nearby_atoms_{min_nearby_atoms}_'
                'radius_{radius_A}'
        )
        output_path = Path(
                args['--output-path']
                    .replace('%', default_output_path)
                    .format(**path_params)
        )

        try:
            save_origin_params(
                    output_path,
                    tags=pisces_df['tag'],
                    origin_params=origin_params, 
                    force=args['--force'],
            )
        except FileExistsError:
            print(f"Output path already exists: {output_path}")
            print("Aborting!  Use `-f` to overwrite.")
            raise SystemExit

    if args['calc']:
        output_path = Path(args['<output_dir>'])
        num_workers = int(args['<num_workers>'] or 1)
        worker_id = int(args['<worker_id>'] or 0)

        if worker_id >= num_workers:
            print(f"Worker id ({worker_id}) must be less than number of workers ({num_workers})")

        tags, origin_params = load_origin_params(output_path)
        chunk = nth(chunked(tags, num_workers), worker_id)

        origins, status = choose_origins_for_tags(tqdm(chunk), origin_params)
        save_origins(output_path, origins, status, (worker_id, num_workers))

    if args['finish']:
        output_path = Path(args['<output_dir>'])
        _, status = consolidate_origins(output_path, dry_run=args['--dry-run'])

        print(f"Loaded {len(status['tags_loaded'])} structures.")
        print(f"Skipped {len(status['tags_skipped'])} structures.")

        tags, _ = load_origin_params(output_path)
        tags_missing = set(tags) - set(status['tags_loaded'] + status['tags_skipped'])

        print(f"Pending {len(tags_missing)} structures.")


